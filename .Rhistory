X2021_data1<-X2021_data1[-1,]
X2021_data2<-A100_A199_Maths_Dept_21.2.24[,25:ncol(A100_A199_Maths_Dept_21.2.24)] # Data with years results
colnames(X2021_data2)<-X2021_data2[1,]
X2021_data2<-X2021_data2[-1,]
X2021_combined<-cbind(X2021_data1,X2021_data2) # Combine the two datasets
X2022_data1<-X07_12_23_Data_for_Maths_Department[-1,1:24] # Reading data without first year results
X2022_data2<-X07_12_23_Data_for_Maths_Department[,25:ncol(X07_12_23_Data_for_Maths_Department)] # First year results
colnames(X2022_data2) <- X2022_data2[1, ] # Naming the columns with the values of the first row
X2022_data2<-X2022_data2[-1,] # Remove the first row
X2022_combined<-cbind(X2022_data1,X2022_data2) # Combine the two datasets
# subset 2020 data set
cols_2020=c('GCSE Score','Verbal Reasoning Score','Decision Making Score',
'Quantitative Reasoning Score','Abstract Reasoning Score',
'Situational Judgement Band', 'UKCAT Score',
'Station 1 - Total','Station 2 - Total',
'Station 3 -Total','Station 4 - Total','Station 5 -Total',
'Station 6 - Total','Station 7 - Total','Station 8 - Total',
'Total Out of 135')
# subset 2021 data set
cols_2021=c('GCSE_Score','Verbal Reasoning Score','Decision Making Score',
'Quantitative Reasoning Score','Abstract Reasoning Score',
'Situational Judgement Band','UKCAT_Score','Station 1 - Total',
'Station 2 - Total','Station 3 -Total','Station 4 - Total',
'Station 5 - Total','Station 6 - Total','Total_MMI_Score')
# subset 2022 data set
cols_2022=c('GCSE_Score','Verbal Reasoning Score', 'Decision Making Score',
'Quantitative Reasoning Score','Abstract Reasoning Score',
'Situational Judgement Band','UKCAT_Score','Station 1 - Total',
'Station 2 - Total','Station 3 -Total', 'Station 4 - Total',
'Station 5 - Total','Station 6 - Total','Station 7_QR_Total',
'Total_MMI_Score')
col_names_2020<-c('GCSE_Score', 'Verbal_Reasoning_Score','Decision_Making_Score',
'Quantitative_Reasoning_Score','Abstract_Reasoning_Score',
'Situational_Judgement_Band','UKCAT_Score','Station1','Station2',
'Station3', 'Station4', 'Station5','Station6','Station7',
'Station8','Total_MMI_Score')
col_names_2021<-c('GCSE_Score', 'Verbal_Reasoning_Score','Decision_Making_Score',
'Quantitative_Reasoning_Score','Abstract_Reasoning_Score',
'Situational_Judgement_Band','UKCAT_Score','Station1','Station2',
'Station3', 'Station4', 'Station5','Station6','Total_MMI_Score')
col_names_2022<-c('GCSE_Score', 'Verbal_Reasoning_Score','Decision_Making_Score',
'Quantitative_Reasoning_Score','Abstract_Reasoning_Score',
'Situational_Judgement_Band','UKCAT_Score','Station1','Station2',
'Station3', 'Station4', 'Station5','Station6','Station7',
'Total_MMI_Score')
df_2020<-X2020_combined[,cols_2020]
colnames(df_2020)<-col_names_2020
# Converting all columns to numeric except 'Situational_Judgement_Band'
df_2020[, -which(names(df_2020) == 'Situational_Judgement_Band')] <-
lapply(df_2020[, -which(names(df_2020) == 'Situational_Judgement_Band')], as.numeric)
df_2021<-X2021_combined[,cols_2021]
colnames(df_2021)<-col_names_2021
# Converting all columns to numeric except 'Situational_Judgement_Band'
df_2021[, -which(names(df_2021) == 'Situational_Judgement_Band')] <-
lapply(df_2021[, -which(names(df_2021) == 'Situational_Judgement_Band')], as.numeric)
df_2022<-X2022_combined[,cols_2022]
colnames(df_2022)<-col_names_2022
df_2020$total=df_2020$UKCAT_Score+df_2020$GCSE_Score
df_2021$total=df_2021$UKCAT_Score+df_2021$GCSE_Score
df_2022$total=df_2022$UKCAT_Score+df_2022$GCSE_Score
df_2020$Interview <- ifelse(rowSums(is.na(df_2020[, grepl("^Station", names(df_2020))])) == 8 & df_2020$Situational_Judgement_Band == "BAND 4", 0, 1)
df_2021$Interview <- ifelse(rowSums(is.na(df_2021[, grepl("^Station", names(df_2021))])) == 8 & df_2021$Situational_Judgement_Band == "BAND 4", 0, 1)
df_2022$Interview <- ifelse(rowSums(is.na(df_2022[, grepl("^Station", names(df_2022))])) == 7, 0, 1)
# Let's get the number of applicants who were interviewed in each year
number_interviewed_2020<-as.numeric(sum(df_2020$Interview))
number_interviewed_2021<-as.numeric(sum(df_2021$Interview,na.rm = TRUE))
number_interviewed_2022<-as.numeric(sum(df_2022$Interview,na.rm = TRUE))
# Summary Statistics
st(df_2020)
st(df_2021)
st(df_2022)
# Let's see the relationship that exists between any two MMIs by use of
# a correlogram in every year
library(corrplot)
# Filtering only interviewed applicants.
df_2020_interviewed<-df_2020%>%
filter(Interview==1)
df_2021_interviewed<-df_2021%>%
filter(Interview==1)
df_2022_interviewed<-df_2022%>%
filter(Interview==1)
#2020
df_2020_interviewed_corr_data<-df_2020_interviewed[, grepl("^Station", names(df_2020_interviewed))] # Extract only MMI data
correlation_matrix_2020 <- cor(df_2020_interviewed_corr_data)
corrplot(correlation_matrix_2020, method = "circle", addCoef.col = "black")
#2021
df_2021_interviewed_corr_data<-df_2021_interviewed[, grepl("^Station", names(df_2021_interviewed))] # Extract only MMI data
df_2021_interviewed_corr_data<-df_2021_interviewed_corr_data%>%
na.omit() # remove any missing values
correlation_matrix_2021 <- cor(df_2021_interviewed_corr_data)
corrplot(correlation_matrix_2021, method = "circle", addCoef.col = "black")
#2022
df_2022_interviewed_corr_data<-df_2022_interviewed[, grepl("^Station", names(df_2022_interviewed))] # Extract only MMI data
df_2022_interviewed_corr_data<-df_2022_interviewed_corr_data%>%
na.omit() # remove any missing values
correlation_matrix_2022 <- cor(df_2022_interviewed_corr_data)
corrplot(correlation_matrix_2022, method = "circle", addCoef.col = "black")
#2020
reg_model_2020<-lm(Total_MMI_Score~total,data =df_2020_interviewed )
summary(reg_model_2020)
# Scatterplot with regression line and equation
ggplot(df_2020_interviewed, aes(x = total, y = Total_MMI_Score)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, color = "red") +
stat_regline_equation(label.x = 30, label.y = 130,
aes(label = paste(after_stat(eq.label), after_stat(rr.label),
sep = "~~~~")), formula = y ~ x) +
labs(x = "Total = GCSE + UKCAT Score", y = "Total MMI Score") +
theme_bw()
#2021
reg_model_2021<-lm(Total_MMI_Score~total,data =df_2021_interviewed )
summary(reg_model_2021)
# Scatterplot with regression line and equation
ggplot(df_2021_interviewed, aes(x = total, y = Total_MMI_Score)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, color = "red") +
stat_regline_equation(label.x = 30, label.y = 120,
aes(label = paste(after_stat(eq.label), after_stat(rr.label),
sep = "~~~~")), formula = y ~ x) +
labs(x = "Total = GCSE + UKCAT Score", y = "Total MMI Score") +
theme_bw()
#2022
reg_model_2022<-lm(Total_MMI_Score~total,data =df_2022_interviewed)
summary(reg_model_2022)
# Scatterplot with regression line and equation
ggplot(df_2022_interviewed, aes(x = total, y = Total_MMI_Score)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, color = "red") +
stat_regline_equation(label.x = 30, label.y = 130,
aes(label = paste(after_stat(eq.label), after_stat(rr.label),
sep = "~~~~")), formula = y ~ x) +
labs(x = "Total = GCSE + UKCAT Score", y = "Total MMI Score") +
theme_bw()
library(stats)
library(caret)
#2020
# Standardize the data
scaled_data_20 <- scale(df_2020[, c('Station1','Station2',
'Station3','Station4','Station5',
'Station6','Station7','Station8')])
# Perform PCA
pca_result_20 <- prcomp(na.omit(scaled_data_20), scale. = TRUE)
# Select number of components to retain (e.g., based on variance explained)
# You can use the summary(pca_result_20) to see the variance explained by each component
num_components <- 2
# Transform data using selected components
pcs_data_20 <- data.frame(predict(pca_result_20, scaled_data_20)[, 1:num_components])
pca_data_20=cbind(df_2020$Interview,pcs_data_20$PC1, pcs_data_20$PC2)
colnames(pca_data_20)=c('Interview','PC1', 'PC2')
pca_data_20[is.na(pca_data_20)] <- 0
pca_data_20=data.frame(pca_data_20)
# Fit regression model
model_2020 <- glm(Interview ~. , data =pca_data_20, family = binomial)
# Summary of the model
summary(model_2020)
# Standardize the data
scaled_data_21 <- scale(df_2021[, c('Station1','Station2',
'Station3','Station4','Station5',
'Station6')])
# Perform PCA
pca_result_21 <- prcomp(na.omit(scaled_data_21), scale. = TRUE)
# Select number of components to retain (e.g., based on variance explained)
# You can use the summary(pca_result_21) to see the variance explained by each component
num_components <- 2
# Transform data using selected components
pcs_data_21 <- data.frame(predict(pca_result_21, scaled_data_21)[, 1:num_components])
pca_data_21=cbind(df_2021$Interview,pcs_data_21$PC1, pcs_data_21$PC2)
colnames(pca_data_21)=c('Interview','PC1', 'PC2')
pca_data_21[is.na(pca_data_21)] <- 0
pca_data_21=data.frame(pca_data_21)
# Fit regression model
model_2021 <- glm(Interview ~. , data =pca_data_21, family = binomial)
# Summary of the model
summary(model_2021)
# Standardize the data
scaled_data_22 <- scale(df_2022[, c('Station1','Station2',
'Station3','Station4','Station5',
'Station6','Station7')])
# Perform PCA
pca_result_22 <- prcomp(na.omit(scaled_data_22), scale. = TRUE)
# Select number of components to retain (e.g., based on variance explained)
# You can use the summary(pca_result_22) to see the variance explained by each component
num_components <- 2
# Transform data using selected components
pcs_data_22 <- data.frame(predict(pca_result_22, scaled_data_22)[, 1:num_components])
pca_data_22=cbind(df_2022$Interview,pcs_data_22$PC1, pcs_data_22$PC2)
colnames(pca_data_22)=c('Interview','PC1', 'PC2')
pca_data_22[is.na(pca_data_22)] <- 0
pca_data_22=data.frame(pca_data_22)
# Fit regression model
model_2022 <- glm(Interview ~. , data =pca_data_22, family = binomial)
# Summary of the model
summary(model_2022)
library(lmtest)  # For Breusch-Pagan test
library(car)     # For remedial measures (optional)
library(stargazer)
library(olsrr) # For Step-wise regression
# Create an empty list to store the models
models_2020 <- list()
models_2021 <- list()
models_2022 <- list()
# Define stations as a character vector for readability
stations_2020 <- c("Station1", "Station2",'Station3','Station4','Station5','Station6', "Station7","Station8")
# Loop over each station
for (station in stations_2020) {
# Define formula with current station as dependent variable
full_formula <- paste(station, "~  Verbal_Reasoning_Score + Decision_Making_Score + Quantitative_Reasoning_Score + Abstract_Reasoning_Score + GCSE_Score", sep = "")
# Fit the full model
full_model <- glm(full_formula, data = df_2020_interviewed)
models_2020[[station]] <- full_model
}
stations_2021 <- c("Station1", "Station2",'Station3','Station4','Station5','Station6')
# Loop over each station
for (station in stations_2021) {
# Define formula with current station as dependent variable
full_formula <- paste(station, "~ Verbal_Reasoning_Score + Decision_Making_Score + Quantitative_Reasoning_Score + Abstract_Reasoning_Score + GCSE_Score", sep = "")
# Fit the full model
full_model <- glm(full_formula, data = df_2021_interviewed)
# Store the model in the list
models_2021[[station]] <- full_model
}
stations_2022 <- c("Station1", "Station2",'Station3','Station4','Station5','Station6', "Station7")
# Loop over each station
for (station in stations_2022) {
# Define formula with current station as dependent variable
full_formula <- paste(station, "~ Verbal_Reasoning_Score + Decision_Making_Score + Quantitative_Reasoning_Score + Abstract_Reasoning_Score + GCSE_Score", sep = "")
# Fit the full model
full_model <- glm(full_formula, data = df_2022_interviewed)
models_2022[[station]] <- full_model
}
# Create a stargazer table for the results
stargazer(models_2020, type = "text",
title = "GLM Results for 2020", adjust = TRUE, out = 'models1.docx',report=('vc*p'))
# Create a stargazer table for the results
stargazer(models_2020, type = "text",
title = "GLM Full Model Results for 2020", adjust = TRUE, out = 'models1.docx',report=('vc*p'))
dat<-mtcars
View(dat)
library(lattice)
dat1<-crabs
dat1<-data(crabs)
library(MASS)
dat1<-data(cabbages)
dat1<-cabbages
View(cabbages)
dat1<-Nile
dat1<-as.data.frame(Nile)
View(dat1)
View(cabbages)
dat2<-cabbages
View(dat2)
View(dat2)
View(dat2)
names(cabbages)
plot(cabbages$HeadWt,cabbages$VitC,type = 'l', col='blue',
lty=1,main = "Comparison of Cabbage Trends", xlab = "Head Weight", ylab = "Vitc")
View(dat)
lines(cabbages$HeadWt,(cabbages$VitC)^2,type = 'l', col='red', lty=2)
plot(cabbages$HeadWt,cabbages$VitC,type = 'l', col='blue',
lty=1,main = "Comparison of Cabbage Trends", xlab = "Head Weight", ylab = "Vitc")
lines(cabbages$HeadWt,(cabbages$VitC)^2,type = 'l', col='red', lty=2)
legend("topright", legend = c("Trend 1", "Trend 2"), col = c("blue", "red"), lty = c(1, 2))
plot(cabbages$HeadWt,cabbages$VitC,type = 'l', col='blue',
lty=1,main = "Comparison of Cabbage Trends", xlab = "Head Weight", ylab = "Vitc")
lines(cabbages$HeadWt,(cabbages$VitC)^2,type = 'l', col='red', lty=2)
legend("topright", legend = c("Head Weight", "VitC Squared"), col = c("blue", "red"), lty = c(1, 2))
plot(cabbages$HeadWt,cabbages$VitC,type = 'l', col='blue',
lty=1,main = "Comparison of Cabbage Trends", xlab = "Head Weight", ylab = "Vitc")
lines(cabbages$HeadWt,(cabbages$VitC)^4,type = 'l', col='red', lty=2)
legend("topright", legend = c("Head Weight", "VitC Squared"), col = c("blue", "red"), lty = c(1, 2))
plot(cabbages$HeadWt,cabbages$VitC,type = 'l', col='blue',
lty=1,main = "Comparison of Cabbage Trends", xlab = "Head Weight", ylab = "Vitc")
lines(cabbages$HeadWt,(cabbages$VitC)^2,type = 'l', col='red', lty=2)
legend("topright", legend = c("Head Weight", "VitC Squared"), col = c("blue", "red"), lty = c(1, 2))
# Assuming your dataframe is called 'cabbages'
unique_headwt <- unique(cabbages$HeadWt)
library(dplyr)
unique_cabbages <- cabbages %>%
distinct(HeadWt, .keep_all = TRUE) %>%
arrange(desc(HeadWt))
View(unique_cabbages)
plot(unique_cabbages$HeadWt,unique_cabbages$VitC,type = 'l', col='blue',
lty=1,main = "Comparison of Cabbage Trends", xlab = "Head Weight", ylab = "Vitc")
lines(unique_cabbages$HeadWt,(unique_cabbages$VitC)^2,type = 'l', col='red', lty=2)
legend("topright", legend = c("Head Weight", "VitC Squared"), col = c("blue", "red"), lty = c(1, 2))
unique_cabbages <- cabbages %>%
distinct(HeadWt, .keep_all = TRUE) %>%
arrange(desc(HeadWt,FALSE))
unique_cabbages <- cabbages %>%
distinct(HeadWt, .keep_all = TRUE) %>%
arrange(desc(HeadWt))
unique_cabbages <- cabbages %>%
distinct(HeadWt, .keep_all = TRUE) %>%
arrange(desc(HeadWt),FALSE)
View(unique_cabbages)
# Solution
library(dplyr)
library(MASS)
cabbages <- cabbages %>%
distinct(HeadWt, .keep_all = TRUE) %>%
arrange(desc(HeadWt),FALSE)
plot(cabbages$HeadWt,(cabbages$HeadWt)^2,type = 'l', col='blue',
lty=1,main = "Comparison of Unique Cabbage Trends", xlab = "Head Weight", ylab = "Vitc")
lines(cabbages$HeadWt,(cabbages$HeadWt)^3,type = 'l', col='red', lty=2)
legend("topright", legend = c("Head Weight", "VitC Squared"), col = c("blue", "red"), lty = c(1, 2))
plot(cabbages$HeadWt,(cabbages$HeadWt)^2,type = 'l', col='blue',
lty=1,main = "Comparison of Unique Cabbage Trends", xlab = "Head Weight", ylab = "Vitc")
lines(cabbages$HeadWt,(cabbages$HeadWt)^3,type = 'l', col='red', lty=2)
legend("topleft", legend = c("Head Weight", "VitC Squared"), col = c("blue", "red"), lty = c(1, 2))
plot(cabbages$HeadWt,(cabbages$HeadWt)^2,type = 'l', col='blue',
lty=1,main = "Comparison of Unique Cabbage Trends", xlab = "Head Weight", ylab = "")
lines(cabbages$HeadWt,(cabbages$HeadWt)^3,type = 'l', col='red', lty=2)
legend("topleft", legend = c("Head Weight Square", "Cube of Head Weight "), col = c("blue", "red"), lty = c(1, 2))
plot(cabbages$HeadWt,(cabbages$HeadWt)^2,type = 'l', col='blue',
lty=1,main = "Comparison of Unique Cabbage Trends", xlab = "Head Weight", ylab = "")
lines(cabbages$HeadWt,(cabbages$HeadWt)^3,type = 'l', col='red', lty=2)
legend("topleft", legend = c("Square of Head Weight", "Cube of Head Weight "), col = c("blue", "red"), lty = c(1, 2))
?locator()
# Creating a scatter plot
plot(iris$Sepal.Length, iris$Petal.Length,
main = "Scatter Plot and Regression Line of Sepal Length vs Petal Length",
xlab = "Sepal Length", ylab = "Petal Length",
col = "blue")
# Fit linear regression model
model <- lm(Petal.Length ~ Sepal.Length, data = iris)
# Adding regression line
abline(model, col = "red")
# Adding regression equation
eq <- paste("y =", round(coef(model)[1], 2), "+", round(coef(model)[2], 2), "x")
text(6, 7, eq, pos = 4)
# Adding confidence intervals
conf_interval <- predict(model, interval = "confidence")
lines(iris$Sepal.Length, conf_interval[, "lwr"], col = "green", lty = 2)
lines(iris$Sepal.Length, conf_interval[, "upr"], col = "green", lty = 2)
# Creating a scatter plot
plot(iris$Sepal.Length, iris$Petal.Length,
main = "Scatter Plot and Regression Line of Sepal Length vs Petal Length",
xlab = "Sepal Length", ylab = "Petal Length",
col = "blue")
# Fit linear regression model
model <- lm(Petal.Length ~ Sepal.Length, data = iris)
# Adding regression line
abline(model, col = "red")
# Adding regression equation
eq <- paste("y =", round(coef(model)[1], 2), "+", round(coef(model)[2], 2), "x")
text(6, 7, eq, pos = 4)
# Adding confidence intervals
conf_interval <- predict(model, interval = "confidence")
lines(iris$Sepal.Length, conf_interval[, "lwr"], col = "green", lty = 2)
lines(iris$Sepal.Length, conf_interval[, "upr"], col = "green", lty = 2)
# Add legend
legend("topright", legend = c("Data", "Regression Line", "Confidence Intervals"),
col = c("blue", "red", "green"), lty = c(NA, 1, 2), lwd = c(NA, 1, 1),
pch = c(1, NA, NA), bty = "n")
# Creating a scatter plot
plot(iris$Sepal.Length, iris$Petal.Length,
main = "Scatter Plot and Regression Line of Sepal Length vs Petal Length",
xlab = "Sepal Length", ylab = "Petal Length",
col = "blue")
# Fit linear regression model
model <- lm(Petal.Length ~ Sepal.Length, data = iris)
# Adding regression line
abline(model, col = "red")
# Adding regression equation
eq <- paste("y =", round(coef(model)[1], 2), "+", round(coef(model)[2], 2), "x")
text(6, 7, eq, pos = 4)
# Adding confidence intervals
conf_interval <- predict(model, interval = "confidence")
lines(iris$Sepal.Length, conf_interval[, "lwr"], col = "green", lty = 2)
lines(iris$Sepal.Length, conf_interval[, "upr"], col = "green", lty = 2)
# Add legend
legend("bottomright", legend = c("Data", "Regression Line", "Confidence Intervals"),
col = c("blue", "red", "green"), lty = c(NA, 1, 2), lwd = c(NA, 1, 1),
pch = c(1, NA, NA), bty = "n")
# Creating a scatter plot
plot(iris$Sepal.Length, iris$Petal.Length,
main = "Scatter Plot and Regression Line of Sepal Length vs Petal Length",
xlab = "Sepal Length", ylab = "Petal Length",
col = "blue")
# Fit linear regression model
model <- lm(Petal.Length ~ Sepal.Length, data = iris)
# Adding regression line
abline(model, col = "red")
# Adding regression equation
eq <- paste("y =", round(coef(model)[1], 2), "+", round(coef(model)[2], 2), "x")
text(6, 7, eq, pos = 4)
# Adding confidence intervals
conf_interval <- predict(model, interval = "confidence")
lines(iris$Sepal.Length, conf_interval[, "lwr"], col = "green", lty = 2)
lines(iris$Sepal.Length, conf_interval[, "upr"], col = "green", lty = 2)
# Add legend
legend("topleft", legend = c("Data", "Regression Line", "Confidence Intervals"),
col = c("blue", "red", "green"), lty = c(NA, 1, 2), lwd = c(NA, 1, 1),
pch = c(1, NA, NA), bty = "n")
# Creating a scatter plot
plot(iris$Sepal.Length, iris$Petal.Length,
main = "Scatter Plot and Regression Line of Sepal Length vs Petal Length",
xlab = "Sepal Length", ylab = "Petal Length",
col = "blue")
# Fit linear regression model
model <- lm(Petal.Length ~ Sepal.Length, data = iris)
# Adding regression line
abline(model, col = "red")
# Adding regression equation
eq <- paste("y =", round(coef(model)[1], 2), "+", round(coef(model)[2], 2), "x")
text(6.5, 2.5, eq, pos = 4)
# Adding confidence intervals
conf_interval <- predict(model, interval = "confidence")
lines(iris$Sepal.Length, conf_interval[, "lwr"], col = "green", lty = 2)
lines(iris$Sepal.Length, conf_interval[, "upr"], col = "green", lty = 2)
# Add legend
legend("topleft", legend = c("Data", "Regression Line", "Confidence Intervals"),
col = c("blue", "red", "green"), lty = c(NA, 1, 2), lwd = c(NA, 1, 1),
pch = c(1, NA, NA), bty = "n")
# Creating a scatter plot
plot(iris$Sepal.Length, iris$Petal.Length,
main = "Scatter Plot and Regression Line of Sepal Length vs Petal Length",
xlab = "Sepal Length", ylab = "Petal Length",
col = "blue")
# Fit linear regression model
model <- lm(Petal.Length ~ Sepal.Length, data = iris)
# Adding regression line
abline(model, col = "red")
# Adding regression equation
eq <- paste("y =", round(coef(model)[1], 2), "+", round(coef(model)[2], 2), "x")
text(6.5, 2.5, eq, pos = 4)
# Adding confidence intervals
conf_interval <- predict(model, interval = "confidence")
lines(iris$Sepal.Length, conf_interval[, "lwr"], col = "green", lty = 2)
lines(iris$Sepal.Length, conf_interval[, "upr"], col = "green", lty = 2)
# Add legend
legend("topleft", legend = c("Data", "Regression Line", "Confidence Intervals"),
col = c("blue", "red", "green"), lty = c(NA, 1, 2), lwd = c(NA, 1, 1),
pch = c(1, NA, NA), bty = "o")
# Creating a scatter plot
plot(iris$Sepal.Length, iris$Petal.Length,
main = "Scatter Plot and Regression Line of Sepal Length vs Petal Length",
xlab = "Sepal Length", ylab = "Petal Length",
col = "blue")
# Fit linear regression model
model <- lm(Petal.Length ~ Sepal.Length, data = iris)
# Adding regression line
abline(model, col = "red")
# Adding regression equation
eq <- paste("y =", round(coef(model)[1], 2), "+", round(coef(model)[2], 2), "x")
text(6.5, 2.5, eq, pos = 4)
# Adding confidence intervals
conf_interval <- predict(model, interval = "confidence")
lines(iris$Sepal.Length, conf_interval[, "lwr"], col = "green", lty = 2)
lines(iris$Sepal.Length, conf_interval[, "upr"], col = "green", lty = 2)
# Add legend
legend("topleft", legend = c("Data", "Regression Line", "Confidence Intervals"),
col = c("blue", "red", "green"), lty = c(NA, 1, 2), lwd = c(NA, 1, 1),
pch = c(1, NA, NA), bty = "o" # Enclose the legend in a box
)
# Creating a scatter plot
plot(iris$Sepal.Length, iris$Petal.Length,
main = "Scatter Plot and Regression Line of Sepal Length vs Petal Length",
xlab = "Sepal Length", ylab = "Petal Length",
col = "blue")
# Fit linear regression model
model <- lm(Petal.Length ~ Sepal.Length, data = iris)
# Adding regression line
abline(model, col = "red")
# Adding regression equation
eq <- paste("y =", round(coef(model)[1], 2), "+", round(coef(model)[2], 2), "x")
text(6.5, 2.5, eq, pos = 4)
# Adding confidence intervals
conf_interval <- predict(model, interval = "confidence")
lines(iris$Sepal.Length, conf_interval[, "lwr"], col = "green", lty = 2)
lines(iris$Sepal.Length, conf_interval[, "upr"], col = "green", lty = 2)
# Add legend
legend("topleft", legend = c("Data Points", "Regression Line", "Confidence Intervals"),
col = c("blue", "red", "green"), lty = c(NA, 1, 2), lwd = c(NA, 1, 1),
pch = c(1, NA, NA), bty = "o" # Enclose the legend in a box
)
library(ggplot2)
# Scatter plot with regression line
ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Scatter Plot of Sepal Length vs Sepal Width with Regression Line",
x = "Sepal Length", y = "Sepal Width") +
theme_minimal()
# Scatter plot with regression line
ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Scatter Plot of Sepal Length vs Sepal Width with Regression Line",
x = "Sepal Length", y = "Sepal Width") +
theme_bw()
# Faceted scatter plot
ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
geom_point() +
facet_wrap(~ Species) +
labs(title = "Faceted Scatter Plot of Sepal Length vs Sepal Width",
x = "Sepal Length", y = "Sepal Width") +
theme_minimal()
# Flipped coordinate system
ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
geom_point() +
coord_flip() +
labs(title = "Scatter Plot with Flipped Coordinate System",
x = "Sepal Length", y = "Sepal Width") +
theme_minimal()
# Flipped coordinate system
ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
geom_point() +
coord_flip() +
labs(title = "Scatter Plot with Flipped Coordinate System",
x = "Sepal Length", y = "Sepal Width") +
theme_bw()
