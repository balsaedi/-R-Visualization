library(MASS)
library(tidyverse)
library(ggpubr)
# Set the working directory
setwd("C:/Files/Freelancing/Upwork/2024/Hannah Tranot/Research work/New deliverable/Data/New Data")
Final_for_Maths_Dept_A100_2020_SLD_BI_HJ <- read_excel("Final for Maths Dept._A100 2020.SLD.BI.HJ.xlsx")
A100_A199_Maths_Dept_21.2.24 <- read_excel("Final Version for Maths Dept_21.2.24_A100 2021 & A199 2020.xlsx")
X07_12_23_Data_for_Maths_Department <- read_excel("07.12.23_Data for Maths Department.xlsx")
X2020_data1<-Final_for_Maths_Dept_A100_2020_SLD_BI_HJ[,1:25] # MMI data without results
colnames(X2020_data1)<-X2020_data1[1,]
X2020_data1<-X2020_data1[-1,]
X2020_data2<-Final_for_Maths_Dept_A100_2020_SLD_BI_HJ[,26:ncol(Final_for_Maths_Dept_A100_2020_SLD_BI_HJ)] # Data with years results
colnames(X2020_data2)<-X2020_data2[1,]
X2020_data2<-X2020_data2[-1,]
X2020_combined<-cbind(X2020_data1,X2020_data2)
# ii). Cleaning 2021 data
X2021_data1<-A100_A199_Maths_Dept_21.2.24[,1:24]
colnames(X2021_data1)<-X2021_data1[1,]
X2021_data1<-X2021_data1[-1,]
X2021_data2<-A100_A199_Maths_Dept_21.2.24[,25:ncol(A100_A199_Maths_Dept_21.2.24)] # Data with years results
colnames(X2021_data2)<-X2021_data2[1,]
X2021_data2<-X2021_data2[-1,]
X2021_combined<-cbind(X2021_data1,X2021_data2) # Combine the two datasets
X2022_data1<-X07_12_23_Data_for_Maths_Department[-1,1:24] # Reading data without first year results
X2022_data2<-X07_12_23_Data_for_Maths_Department[,25:ncol(X07_12_23_Data_for_Maths_Department)] # First year results
colnames(X2022_data2) <- X2022_data2[1, ] # Naming the columns with the values of the first row
X2022_data2<-X2022_data2[-1,] # Remove the first row
X2022_combined<-cbind(X2022_data1,X2022_data2) # Combine the two datasets
# subset 2020 data set
cols_2020=c('GCSE Score','Verbal Reasoning Score','Decision Making Score',
'Quantitative Reasoning Score','Abstract Reasoning Score',
'Situational Judgement Band', 'UKCAT Score',
'Station 1 - Total','Station 2 - Total',
'Station 3 -Total','Station 4 - Total','Station 5 -Total',
'Station 6 - Total','Station 7 - Total','Station 8 - Total',
'Total Out of 135')
# subset 2021 data set
cols_2021=c('GCSE_Score','Verbal Reasoning Score','Decision Making Score',
'Quantitative Reasoning Score','Abstract Reasoning Score',
'Situational Judgement Band','UKCAT_Score','Station 1 - Total',
'Station 2 - Total','Station 3 -Total','Station 4 - Total',
'Station 5 - Total','Station 6 - Total','Total_MMI_Score')
# subset 2022 data set
cols_2022=c('GCSE_Score','Verbal Reasoning Score', 'Decision Making Score',
'Quantitative Reasoning Score','Abstract Reasoning Score',
'Situational Judgement Band','UKCAT_Score','Station 1 - Total',
'Station 2 - Total','Station 3 -Total', 'Station 4 - Total',
'Station 5 - Total','Station 6 - Total','Station 7_QR_Total',
'Total_MMI_Score')
col_names_2020<-c('GCSE_Score', 'Verbal_Reasoning_Score','Decision_Making_Score',
'Quantitative_Reasoning_Score','Abstract_Reasoning_Score',
'Situational_Judgement_Band','UKCAT_Score','Station1','Station2',
'Station3', 'Station4', 'Station5','Station6','Station7',
'Station8','Total_MMI_Score')
col_names_2021<-c('GCSE_Score', 'Verbal_Reasoning_Score','Decision_Making_Score',
'Quantitative_Reasoning_Score','Abstract_Reasoning_Score',
'Situational_Judgement_Band','UKCAT_Score','Station1','Station2',
'Station3', 'Station4', 'Station5','Station6','Total_MMI_Score')
col_names_2022<-c('GCSE_Score', 'Verbal_Reasoning_Score','Decision_Making_Score',
'Quantitative_Reasoning_Score','Abstract_Reasoning_Score',
'Situational_Judgement_Band','UKCAT_Score','Station1','Station2',
'Station3', 'Station4', 'Station5','Station6','Station7',
'Total_MMI_Score')
df_2020<-X2020_combined[,cols_2020]
colnames(df_2020)<-col_names_2020
# Converting all columns to numeric except 'Situational_Judgement_Band'
df_2020[, -which(names(df_2020) == 'Situational_Judgement_Band')] <-
lapply(df_2020[, -which(names(df_2020) == 'Situational_Judgement_Band')], as.numeric)
df_2021<-X2021_combined[,cols_2021]
colnames(df_2021)<-col_names_2021
# Converting all columns to numeric except 'Situational_Judgement_Band'
df_2021[, -which(names(df_2021) == 'Situational_Judgement_Band')] <-
lapply(df_2021[, -which(names(df_2021) == 'Situational_Judgement_Band')], as.numeric)
df_2022<-X2022_combined[,cols_2022]
colnames(df_2022)<-col_names_2022
df_2020$total=df_2020$UKCAT_Score+df_2020$GCSE_Score
df_2021$total=df_2021$UKCAT_Score+df_2021$GCSE_Score
df_2022$total=df_2022$UKCAT_Score+df_2022$GCSE_Score
df_2020$Interview <- ifelse(rowSums(is.na(df_2020[, grepl("^Station", names(df_2020))])) == 8 & df_2020$Situational_Judgement_Band == "BAND 4", 0, 1)
df_2021$Interview <- ifelse(rowSums(is.na(df_2021[, grepl("^Station", names(df_2021))])) == 8 & df_2021$Situational_Judgement_Band == "BAND 4", 0, 1)
df_2022$Interview <- ifelse(rowSums(is.na(df_2022[, grepl("^Station", names(df_2022))])) == 7, 0, 1)
# Let's get the number of applicants who were interviewed in each year
number_interviewed_2020<-as.numeric(sum(df_2020$Interview))
number_interviewed_2021<-as.numeric(sum(df_2021$Interview,na.rm = TRUE))
number_interviewed_2022<-as.numeric(sum(df_2022$Interview,na.rm = TRUE))
# Summary Statistics
st(df_2020)
st(df_2021)
st(df_2022)
# Let's see the relationship that exists between any two MMIs by use of
# a correlogram in every year
library(corrplot)
# Filtering only interviewed applicants.
df_2020_interviewed<-df_2020%>%
filter(Interview==1)
df_2021_interviewed<-df_2021%>%
filter(Interview==1)
df_2022_interviewed<-df_2022%>%
filter(Interview==1)
#2020
df_2020_interviewed_corr_data<-df_2020_interviewed[, grepl("^Station", names(df_2020_interviewed))] # Extract only MMI data
correlation_matrix_2020 <- cor(df_2020_interviewed_corr_data)
corrplot(correlation_matrix_2020, method = "circle", addCoef.col = "black")
#2021
df_2021_interviewed_corr_data<-df_2021_interviewed[, grepl("^Station", names(df_2021_interviewed))] # Extract only MMI data
df_2021_interviewed_corr_data<-df_2021_interviewed_corr_data%>%
na.omit() # remove any missing values
correlation_matrix_2021 <- cor(df_2021_interviewed_corr_data)
corrplot(correlation_matrix_2021, method = "circle", addCoef.col = "black")
#2022
df_2022_interviewed_corr_data<-df_2022_interviewed[, grepl("^Station", names(df_2022_interviewed))] # Extract only MMI data
df_2022_interviewed_corr_data<-df_2022_interviewed_corr_data%>%
na.omit() # remove any missing values
correlation_matrix_2022 <- cor(df_2022_interviewed_corr_data)
corrplot(correlation_matrix_2022, method = "circle", addCoef.col = "black")
#2020
reg_model_2020<-lm(Total_MMI_Score~total,data =df_2020_interviewed )
summary(reg_model_2020)
# Scatterplot with regression line and equation
ggplot(df_2020_interviewed, aes(x = total, y = Total_MMI_Score)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, color = "red") +
stat_regline_equation(label.x = 30, label.y = 130,
aes(label = paste(after_stat(eq.label), after_stat(rr.label),
sep = "~~~~")), formula = y ~ x) +
labs(x = "Total = GCSE + UKCAT Score", y = "Total MMI Score") +
theme_bw()
#2021
reg_model_2021<-lm(Total_MMI_Score~total,data =df_2021_interviewed )
summary(reg_model_2021)
# Scatterplot with regression line and equation
ggplot(df_2021_interviewed, aes(x = total, y = Total_MMI_Score)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, color = "red") +
stat_regline_equation(label.x = 30, label.y = 120,
aes(label = paste(after_stat(eq.label), after_stat(rr.label),
sep = "~~~~")), formula = y ~ x) +
labs(x = "Total = GCSE + UKCAT Score", y = "Total MMI Score") +
theme_bw()
#2022
reg_model_2022<-lm(Total_MMI_Score~total,data =df_2022_interviewed)
summary(reg_model_2022)
# Scatterplot with regression line and equation
ggplot(df_2022_interviewed, aes(x = total, y = Total_MMI_Score)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, color = "red") +
stat_regline_equation(label.x = 30, label.y = 130,
aes(label = paste(after_stat(eq.label), after_stat(rr.label),
sep = "~~~~")), formula = y ~ x) +
labs(x = "Total = GCSE + UKCAT Score", y = "Total MMI Score") +
theme_bw()
library(stats)
library(caret)
#2020
# Standardize the data
scaled_data_20 <- scale(df_2020[, c('Station1','Station2',
'Station3','Station4','Station5',
'Station6','Station7','Station8')])
# Perform PCA
pca_result_20 <- prcomp(na.omit(scaled_data_20), scale. = TRUE)
# Select number of components to retain (e.g., based on variance explained)
# You can use the summary(pca_result_20) to see the variance explained by each component
num_components <- 2
# Transform data using selected components
pcs_data_20 <- data.frame(predict(pca_result_20, scaled_data_20)[, 1:num_components])
View(pcs_data_20)
pca_data_20=cbind(df_2020$Interview,pca_data_20$PC1, pca_data_20$PC2)
pca_data_20=cbind(df_2020$Interview,pcs_data_20$PC1, pcs_data_20$PC2)
colnames(pca_data_20)=c('Interview','PC1', 'PC2')
pca_data_20[is.na(pca_data_20)] <- 0
pca_data_20=data.frame(pca_data_20)
# Fit regression model
model_2020 <- glm(Interview ~. , data =pca_data_20, family = binomial)
# Summary of the model
summary(model_2020)
# Standardize the data
scaled_data_21 <- scale(df_2021[, c('Station1','Station2',
'Station3','Station4','Station5',
'Station6')])
# Perform PCA
pca_result_21 <- prcomp(na.omit(scaled_data_21), scale. = TRUE)
# Select number of components to retain (e.g., based on variance explained)
# You can use the summary(pca_result_21) to see the variance explained by each component
num_components <- 2
# Transform data using selected components
pcs_data_21 <- data.frame(predict(pca_result_21, scaled_data_21)[, 1:num_components])
pca_data_21=cbind(df_2021$Interview,pcs_data_21$PC1, pcs_data_21$PC2)
colnames(pca_data_21)=c('Interview','PC1', 'PC2')
pca_data_21[is.na(pca_data_21)] <- 0
pca_data_21=data.frame(pca_data_21)
# Fit regression model
model_2021 <- glm(Interview ~. , data =pca_data_21, family = binomial)
# Summary of the model
summary(model_2021)
# Standardize the data
scaled_data_22 <- scale(df_2022[, c('Station1','Station2',
'Station3','Station4','Station5',
'Station6','Station7')])
# Perform PCA
pca_result_22 <- prcomp(na.omit(scaled_data_22), scale. = TRUE)
# Select number of components to retain (e.g., based on variance explained)
# You can use the summary(pca_result_22) to see the variance explained by each component
num_components <- 2
# Transform data using selected components
pcs_data_22 <- data.frame(predict(pca_result_22, scaled_data_22)[, 1:num_components])
pca_data_22=cbind(df_2022$Interview,pcs_data_22$PC1, pcs_data_22$PC2)
colnames(pca_data_22)=c('Interview','PC1', 'PC2')
pca_data_22[is.na(pca_data_22)] <- 0
pca_data_22=data.frame(pca_data_22)
# Fit regression model
model_2022 <- glm(Interview ~. , data =pca_data_22, family = binomial)
# Summary of the model
summary(model_2022)
# Summary of the model
summary(model_2020)
# Fit regression model
model_2020 <- glm(Interview ~. , data =pca_data_20, family = binomial)
# Standardize the data
scaled_data_21 <- scale(df_2021[, c('Station1','Station2',
'Station3','Station4','Station5',
'Station6')])
# Perform PCA
pca_result_21 <- prcomp(na.omit(scaled_data_21), scale. = TRUE)
# Select number of components to retain (e.g., based on variance explained)
# You can use the summary(pca_result_21) to see the variance explained by each component
num_components <- 2
# Transform data using selected components
pcs_data_21 <- data.frame(predict(pca_result_21, scaled_data_21)[, 1:num_components])
pca_data_21=cbind(df_2021$Interview,pcs_data_21$PC1, pcs_data_21$PC2)
colnames(pca_data_21)=c('Interview','PC1', 'PC2')
pca_data_21[is.na(pca_data_21)] <- 0
pca_data_21=data.frame(pca_data_21)
# Fit regression model
model_2021 <- glm(Interview ~. , data =pca_data_21, family = binomial)
# Summary of the model
summary(model_2021)
# Standardize the data
scaled_data_22 <- scale(df_2022[, c('Station1','Station2',
'Station3','Station4','Station5',
'Station6','Station7')])
# Perform PCA
pca_result_22 <- prcomp(na.omit(scaled_data_22), scale. = TRUE)
# Select number of components to retain (e.g., based on variance explained)
# You can use the summary(pca_result_22) to see the variance explained by each component
num_components <- 2
# Transform data using selected components
pcs_data_22 <- data.frame(predict(pca_result_22, scaled_data_22)[, 1:num_components])
pca_data_22=cbind(df_2022$Interview,pcs_data_22$PC1, pcs_data_22$PC2)
colnames(pca_data_22)=c('Interview','PC1', 'PC2')
pca_data_22[is.na(pca_data_22)] <- 0
pca_data_22=data.frame(pca_data_22)
# Fit regression model
model_2022 <- glm(Interview ~. , data =pca_data_22, family = binomial)
# Summary of the model
summary(model_2022)
# Load the libraries.
library(readxl)
library(vtable)
library(MASS)
library(tidyverse)
library(ggpubr)
# Set the working directory
setwd("C:/Files/Freelancing/Upwork/2024/Hannah Tranot/Research work/New deliverable/Data/New Data")
Final_for_Maths_Dept_A100_2020_SLD_BI_HJ <- read_excel("Final for Maths Dept._A100 2020.SLD.BI.HJ.xlsx")
A100_A199_Maths_Dept_21.2.24 <- read_excel("Final Version for Maths Dept_21.2.24_A100 2021 & A199 2020.xlsx")
X07_12_23_Data_for_Maths_Department <- read_excel("07.12.23_Data for Maths Department.xlsx")
X2020_data1<-Final_for_Maths_Dept_A100_2020_SLD_BI_HJ[,1:25] # MMI data without results
colnames(X2020_data1)<-X2020_data1[1,]
X2020_data1<-X2020_data1[-1,]
X2020_data2<-Final_for_Maths_Dept_A100_2020_SLD_BI_HJ[,26:ncol(Final_for_Maths_Dept_A100_2020_SLD_BI_HJ)] # Data with years results
colnames(X2020_data2)<-X2020_data2[1,]
X2020_data2<-X2020_data2[-1,]
X2020_combined<-cbind(X2020_data1,X2020_data2)
# ii). Cleaning 2021 data
X2021_data1<-A100_A199_Maths_Dept_21.2.24[,1:24]
colnames(X2021_data1)<-X2021_data1[1,]
X2021_data1<-X2021_data1[-1,]
X2021_data2<-A100_A199_Maths_Dept_21.2.24[,25:ncol(A100_A199_Maths_Dept_21.2.24)] # Data with years results
colnames(X2021_data2)<-X2021_data2[1,]
X2021_data2<-X2021_data2[-1,]
X2021_combined<-cbind(X2021_data1,X2021_data2) # Combine the two datasets
X2022_data1<-X07_12_23_Data_for_Maths_Department[-1,1:24] # Reading data without first year results
X2022_data2<-X07_12_23_Data_for_Maths_Department[,25:ncol(X07_12_23_Data_for_Maths_Department)] # First year results
colnames(X2022_data2) <- X2022_data2[1, ] # Naming the columns with the values of the first row
X2022_data2<-X2022_data2[-1,] # Remove the first row
X2022_combined<-cbind(X2022_data1,X2022_data2) # Combine the two datasets
# subset 2020 data set
cols_2020=c('GCSE Score','Verbal Reasoning Score','Decision Making Score',
'Quantitative Reasoning Score','Abstract Reasoning Score',
'Situational Judgement Band', 'UKCAT Score',
'Station 1 - Total','Station 2 - Total',
'Station 3 -Total','Station 4 - Total','Station 5 -Total',
'Station 6 - Total','Station 7 - Total','Station 8 - Total',
'Total Out of 135')
# subset 2021 data set
cols_2021=c('GCSE_Score','Verbal Reasoning Score','Decision Making Score',
'Quantitative Reasoning Score','Abstract Reasoning Score',
'Situational Judgement Band','UKCAT_Score','Station 1 - Total',
'Station 2 - Total','Station 3 -Total','Station 4 - Total',
'Station 5 - Total','Station 6 - Total','Total_MMI_Score')
# subset 2022 data set
cols_2022=c('GCSE_Score','Verbal Reasoning Score', 'Decision Making Score',
'Quantitative Reasoning Score','Abstract Reasoning Score',
'Situational Judgement Band','UKCAT_Score','Station 1 - Total',
'Station 2 - Total','Station 3 -Total', 'Station 4 - Total',
'Station 5 - Total','Station 6 - Total','Station 7_QR_Total',
'Total_MMI_Score')
col_names_2020<-c('GCSE_Score', 'Verbal_Reasoning_Score','Decision_Making_Score',
'Quantitative_Reasoning_Score','Abstract_Reasoning_Score',
'Situational_Judgement_Band','UKCAT_Score','Station1','Station2',
'Station3', 'Station4', 'Station5','Station6','Station7',
'Station8','Total_MMI_Score')
col_names_2021<-c('GCSE_Score', 'Verbal_Reasoning_Score','Decision_Making_Score',
'Quantitative_Reasoning_Score','Abstract_Reasoning_Score',
'Situational_Judgement_Band','UKCAT_Score','Station1','Station2',
'Station3', 'Station4', 'Station5','Station6','Total_MMI_Score')
col_names_2022<-c('GCSE_Score', 'Verbal_Reasoning_Score','Decision_Making_Score',
'Quantitative_Reasoning_Score','Abstract_Reasoning_Score',
'Situational_Judgement_Band','UKCAT_Score','Station1','Station2',
'Station3', 'Station4', 'Station5','Station6','Station7',
'Total_MMI_Score')
df_2020<-X2020_combined[,cols_2020]
colnames(df_2020)<-col_names_2020
# Converting all columns to numeric except 'Situational_Judgement_Band'
df_2020[, -which(names(df_2020) == 'Situational_Judgement_Band')] <-
lapply(df_2020[, -which(names(df_2020) == 'Situational_Judgement_Band')], as.numeric)
df_2021<-X2021_combined[,cols_2021]
colnames(df_2021)<-col_names_2021
# Converting all columns to numeric except 'Situational_Judgement_Band'
df_2021[, -which(names(df_2021) == 'Situational_Judgement_Band')] <-
lapply(df_2021[, -which(names(df_2021) == 'Situational_Judgement_Band')], as.numeric)
df_2022<-X2022_combined[,cols_2022]
colnames(df_2022)<-col_names_2022
df_2020$total=df_2020$UKCAT_Score+df_2020$GCSE_Score
df_2021$total=df_2021$UKCAT_Score+df_2021$GCSE_Score
df_2022$total=df_2022$UKCAT_Score+df_2022$GCSE_Score
df_2020$Interview <- ifelse(rowSums(is.na(df_2020[, grepl("^Station", names(df_2020))])) == 8 & df_2020$Situational_Judgement_Band == "BAND 4", 0, 1)
df_2021$Interview <- ifelse(rowSums(is.na(df_2021[, grepl("^Station", names(df_2021))])) == 8 & df_2021$Situational_Judgement_Band == "BAND 4", 0, 1)
df_2022$Interview <- ifelse(rowSums(is.na(df_2022[, grepl("^Station", names(df_2022))])) == 7, 0, 1)
# Let's get the number of applicants who were interviewed in each year
number_interviewed_2020<-as.numeric(sum(df_2020$Interview))
number_interviewed_2021<-as.numeric(sum(df_2021$Interview,na.rm = TRUE))
number_interviewed_2022<-as.numeric(sum(df_2022$Interview,na.rm = TRUE))
# Summary Statistics
st(df_2020)
st(df_2021)
st(df_2022)
# Let's see the relationship that exists between any two MMIs by use of
# a correlogram in every year
library(corrplot)
# Filtering only interviewed applicants.
df_2020_interviewed<-df_2020%>%
filter(Interview==1)
df_2021_interviewed<-df_2021%>%
filter(Interview==1)
df_2022_interviewed<-df_2022%>%
filter(Interview==1)
#2020
df_2020_interviewed_corr_data<-df_2020_interviewed[, grepl("^Station", names(df_2020_interviewed))] # Extract only MMI data
correlation_matrix_2020 <- cor(df_2020_interviewed_corr_data)
corrplot(correlation_matrix_2020, method = "circle", addCoef.col = "black")
#2021
df_2021_interviewed_corr_data<-df_2021_interviewed[, grepl("^Station", names(df_2021_interviewed))] # Extract only MMI data
df_2021_interviewed_corr_data<-df_2021_interviewed_corr_data%>%
na.omit() # remove any missing values
correlation_matrix_2021 <- cor(df_2021_interviewed_corr_data)
corrplot(correlation_matrix_2021, method = "circle", addCoef.col = "black")
#2022
df_2022_interviewed_corr_data<-df_2022_interviewed[, grepl("^Station", names(df_2022_interviewed))] # Extract only MMI data
df_2022_interviewed_corr_data<-df_2022_interviewed_corr_data%>%
na.omit() # remove any missing values
correlation_matrix_2022 <- cor(df_2022_interviewed_corr_data)
corrplot(correlation_matrix_2022, method = "circle", addCoef.col = "black")
#2020
reg_model_2020<-lm(Total_MMI_Score~total,data =df_2020_interviewed )
summary(reg_model_2020)
# Scatterplot with regression line and equation
ggplot(df_2020_interviewed, aes(x = total, y = Total_MMI_Score)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, color = "red") +
stat_regline_equation(label.x = 30, label.y = 130,
aes(label = paste(after_stat(eq.label), after_stat(rr.label),
sep = "~~~~")), formula = y ~ x) +
labs(x = "Total = GCSE + UKCAT Score", y = "Total MMI Score") +
theme_bw()
#2021
reg_model_2021<-lm(Total_MMI_Score~total,data =df_2021_interviewed )
summary(reg_model_2021)
# Scatterplot with regression line and equation
ggplot(df_2021_interviewed, aes(x = total, y = Total_MMI_Score)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, color = "red") +
stat_regline_equation(label.x = 30, label.y = 120,
aes(label = paste(after_stat(eq.label), after_stat(rr.label),
sep = "~~~~")), formula = y ~ x) +
labs(x = "Total = GCSE + UKCAT Score", y = "Total MMI Score") +
theme_bw()
#2022
reg_model_2022<-lm(Total_MMI_Score~total,data =df_2022_interviewed)
summary(reg_model_2022)
# Scatterplot with regression line and equation
ggplot(df_2022_interviewed, aes(x = total, y = Total_MMI_Score)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, color = "red") +
stat_regline_equation(label.x = 30, label.y = 130,
aes(label = paste(after_stat(eq.label), after_stat(rr.label),
sep = "~~~~")), formula = y ~ x) +
labs(x = "Total = GCSE + UKCAT Score", y = "Total MMI Score") +
theme_bw()
library(stats)
library(caret)
#2020
# Standardize the data
scaled_data_20 <- scale(df_2020[, c('Station1','Station2',
'Station3','Station4','Station5',
'Station6','Station7','Station8')])
# Perform PCA
pca_result_20 <- prcomp(na.omit(scaled_data_20), scale. = TRUE)
# Select number of components to retain (e.g., based on variance explained)
# You can use the summary(pca_result_20) to see the variance explained by each component
num_components <- 2
# Transform data using selected components
pcs_data_20 <- data.frame(predict(pca_result_20, scaled_data_20)[, 1:num_components])
pca_data_20=cbind(df_2020$Interview,pcs_data_20$PC1, pcs_data_20$PC2)
colnames(pca_data_20)=c('Interview','PC1', 'PC2')
pca_data_20[is.na(pca_data_20)] <- 0
pca_data_20=data.frame(pca_data_20)
# Fit regression model
model_2020 <- glm(Interview ~. , data =pca_data_20, family = binomial)
# Summary of the model
summary(model_2020)
# Standardize the data
scaled_data_21 <- scale(df_2021[, c('Station1','Station2',
'Station3','Station4','Station5',
'Station6')])
# Perform PCA
pca_result_21 <- prcomp(na.omit(scaled_data_21), scale. = TRUE)
# Select number of components to retain (e.g., based on variance explained)
# You can use the summary(pca_result_21) to see the variance explained by each component
num_components <- 2
# Transform data using selected components
pcs_data_21 <- data.frame(predict(pca_result_21, scaled_data_21)[, 1:num_components])
pca_data_21=cbind(df_2021$Interview,pcs_data_21$PC1, pcs_data_21$PC2)
colnames(pca_data_21)=c('Interview','PC1', 'PC2')
pca_data_21[is.na(pca_data_21)] <- 0
pca_data_21=data.frame(pca_data_21)
# Fit regression model
model_2021 <- glm(Interview ~. , data =pca_data_21, family = binomial)
# Summary of the model
summary(model_2021)
# Standardize the data
scaled_data_22 <- scale(df_2022[, c('Station1','Station2',
'Station3','Station4','Station5',
'Station6','Station7')])
# Perform PCA
pca_result_22 <- prcomp(na.omit(scaled_data_22), scale. = TRUE)
# Select number of components to retain (e.g., based on variance explained)
# You can use the summary(pca_result_22) to see the variance explained by each component
num_components <- 2
# Transform data using selected components
pcs_data_22 <- data.frame(predict(pca_result_22, scaled_data_22)[, 1:num_components])
pca_data_22=cbind(df_2022$Interview,pcs_data_22$PC1, pcs_data_22$PC2)
colnames(pca_data_22)=c('Interview','PC1', 'PC2')
pca_data_22[is.na(pca_data_22)] <- 0
pca_data_22=data.frame(pca_data_22)
# Fit regression model
model_2022 <- glm(Interview ~. , data =pca_data_22, family = binomial)
# Summary of the model
summary(model_2022)
library(lmtest)  # For Breusch-Pagan test
library(car)     # For remedial measures (optional)
library(stargazer)
library(olsrr) # For Step-wise regression
# Create an empty list to store the models
models_2020 <- list()
models_2021 <- list()
models_2022 <- list()
# Define stations as a character vector for readability
stations_2020 <- c("Station1", "Station2",'Station3','Station4','Station5','Station6', "Station7","Station8")
# Loop over each station
for (station in stations_2020) {
# Define formula with current station as dependent variable
full_formula <- paste(station, "~  Verbal_Reasoning_Score + Decision_Making_Score + Quantitative_Reasoning_Score + Abstract_Reasoning_Score + GCSE_Score", sep = "")
# Fit the full model
full_model <- glm(full_formula, data = df_2020_interviewed)
models_2020[[station]] <- full_model
}
stations_2021 <- c("Station1", "Station2",'Station3','Station4','Station5','Station6')
# Loop over each station
for (station in stations_2021) {
# Define formula with current station as dependent variable
full_formula <- paste(station, "~ Verbal_Reasoning_Score + Decision_Making_Score + Quantitative_Reasoning_Score + Abstract_Reasoning_Score + GCSE_Score", sep = "")
# Fit the full model
full_model <- glm(full_formula, data = df_2021_interviewed)
# Store the model in the list
models_2021[[station]] <- full_model
}
stations_2022 <- c("Station1", "Station2",'Station3','Station4','Station5','Station6', "Station7")
# Loop over each station
for (station in stations_2022) {
# Define formula with current station as dependent variable
full_formula <- paste(station, "~ Verbal_Reasoning_Score + Decision_Making_Score + Quantitative_Reasoning_Score + Abstract_Reasoning_Score + GCSE_Score", sep = "")
# Fit the full model
full_model <- glm(full_formula, data = df_2022_interviewed)
models_2022[[station]] <- full_model
}
# Create a stargazer table for the results
stargazer(models_2020, type = "text",
title = "GLM Results for 2020", adjust = TRUE, out = 'models1.docx',report=('vc*p'))
# Create a stargazer table for the results
stargazer(models_2020, type = "text",
title = "GLM Full Model Results for 2020", adjust = TRUE, out = 'models1.docx',report=('vc*p'))
